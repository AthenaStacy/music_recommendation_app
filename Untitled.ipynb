{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/py2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# import things\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "from __future__ import division\n",
    "import datetime\n",
    "import nltk\n",
    "#nltk.download()  # Download text data sets, including stop words\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hot100 artist</th>\n",
       "      <th>hot100 track</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_spotify_id</th>\n",
       "      <th>lyrics_body</th>\n",
       "      <th>date</th>\n",
       "      <th>lyrics_clean_no_stopwords</th>\n",
       "      <th>lex_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ricky Nelson</td>\n",
       "      <td>Poor Little Fool</td>\n",
       "      <td>Poor Little Fool</td>\n",
       "      <td>Ricky Nelson</td>\n",
       "      <td>6kGo2CzDxnPP6pxbqABZ7l</td>\n",
       "      <td>I used to play around with hearts\\nThat hasten...</td>\n",
       "      <td>1958-09-13</td>\n",
       "      <td>used play around hearts hastened call met litt...</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>Splish Splash</td>\n",
       "      <td>Splish Splash</td>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>4RxtXFzUxQCOBAbggjN7mM</td>\n",
       "      <td>Splish splash, I was taking a bath\\nLong about...</td>\n",
       "      <td>1958-09-06</td>\n",
       "      <td>splish splash taking bath long saturday night ...</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elvis Presley With The Jordanaires</td>\n",
       "      <td>Hard Headed Woman</td>\n",
       "      <td>Hard Headed Woman</td>\n",
       "      <td>Elvis Presley &amp; The Jordanaires</td>\n",
       "      <td></td>\n",
       "      <td>Well a hard headed woman\\nA soft hearted man\\n...</td>\n",
       "      <td>1958-09-06</td>\n",
       "      <td>well hard headed woman soft hearted man cause ...</td>\n",
       "      <td>0.574468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hot100 artist       hot100 track         track_name  \\\n",
       "0                        Ricky Nelson   Poor Little Fool   Poor Little Fool   \n",
       "2                         Bobby Darin      Splish Splash      Splish Splash   \n",
       "3  Elvis Presley With The Jordanaires  Hard Headed Woman  Hard Headed Woman   \n",
       "\n",
       "                       artist_name        track_spotify_id  \\\n",
       "0                     Ricky Nelson  6kGo2CzDxnPP6pxbqABZ7l   \n",
       "2                      Bobby Darin  4RxtXFzUxQCOBAbggjN7mM   \n",
       "3  Elvis Presley & The Jordanaires                           \n",
       "\n",
       "                                         lyrics_body       date  \\\n",
       "0  I used to play around with hearts\\nThat hasten... 1958-09-13   \n",
       "2  Splish splash, I was taking a bath\\nLong about... 1958-09-06   \n",
       "3  Well a hard headed woman\\nA soft hearted man\\n... 1958-09-06   \n",
       "\n",
       "                           lyrics_clean_no_stopwords  lex_diversity  \n",
       "0  used play around hearts hastened call met litt...       0.604167  \n",
       "2  splish splash taking bath long saturday night ...       0.868421  \n",
       "3  well hard headed woman soft hearted man cause ...       0.574468  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide whether you want to look at Top20 data or Top100 data\n",
    "max_rank = 100 # or 20 if you want\n",
    "if max_rank==20:\n",
    "    filename = 'CleanedLyrics_1950-01-01-2015-01-01MaxRank20'\n",
    "if max_rank==100:\n",
    "    filename = 'CleanedLyricsDF_MaxRank_100'\n",
    "\n",
    "d_lyrics = pd.read_pickle(filename)\n",
    "d_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fields in lyrics data: ['hot100 artist', 'hot100 track', 'track_name', 'artist_name', 'track_spotify_id', 'lyrics_body', 'date', 'lyrics_clean_no_stopwords', 'lex_diversity']\n",
      "(15868, 9)\n"
     ]
    }
   ],
   "source": [
    "#remind ourselves of what the column headers are\n",
    "print 'fields in lyrics data:', list(d.columns.values)\n",
    "print(d_lyrics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool. \n",
    "\n",
    "# Let's make a couple, one with just unigrams, one with just bigrams, \n",
    "# one with just tri-grams, and one with all 3\n",
    "all3_vec = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000, \\\n",
    "                             ngram_range=(1,3)) \n",
    "\n",
    "unigram_vec = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)\n",
    "bigram_vec = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000, \\\n",
    "                             ngram_range=(2,2)) \n",
    "trigram_vec = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000, \\\n",
    "                             ngram_range=(3,3)) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "all3_features = all3_vec.fit_transform(d_lyrics.lyrics_clean_no_stopwords).toarray()\n",
    "unigram_features = unigram_vec.fit_transform(d_lyrics.lyrics_clean_no_stopwords).toarray()\n",
    "bigram_features = bigram_vec.fit_transform(d_lyrics.lyrics_clean_no_stopwords).toarray()\n",
    "trigram_features = trigram_vec.fit_transform(d_lyrics.lyrics_clean_no_stopwords).toarray()\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "# omit the \"toarray()\" above if you want to preserve sparse format\n",
    "\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf weighting -- another way to featurize the words, where rare words are given more weight.\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(all3_features)\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py2]",
   "language": "python",
   "name": "Python [py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
